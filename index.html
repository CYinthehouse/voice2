<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Korean Grammar Coach</title>

  <!-- React + Babel + Tailwind -->
  <script crossorigin src="https://unpkg.com/react@18/umd/react.development.js"></script>
  <script crossorigin src="https://unpkg.com/react-dom@18/umd/react-dom.development.js"></script>
  <script src="https://unpkg.com/@babel/standalone/babel.min.js"></script>
  <script src="https://cdn.tailwindcss.com"></script>

  <!-- Robust ElevenLabs SDK loader: tries multiple CDNs/versions and sets window.ElevenLabs -->
  <script type="module">
    window.loadElevenLabsSDK = async function loadElevenLabsSDK() {
      if (window.ElevenLabs?.Conversation?.startSession) return window.ElevenLabs;

      // Known-working builds (try ESM first, then UMD)
      const candidates = [
        // jsDelivr 0.6.x (ESM)
        "https://cdn.jsdelivr.net/npm/@elevenlabs/client@0.6.2/dist/lib.modern.js",
        "https://cdn.jsdelivr.net/npm/@elevenlabs/client@0.6.1/dist/lib.modern.js",
        "https://cdn.jsdelivr.net/npm/@elevenlabs/client@0.6.0/dist/lib.modern.js",
        // jsDelivr 0.1.6 (ESM + UMD)
        "https://cdn.jsdelivr.net/npm/@elevenlabs/client@0.1.6/dist/lib.modern.js",
        "https://cdn.jsdelivr.net/npm/@elevenlabs/client@0.1.6/dist/lib.umd.js"
      ];

      const tryImport = async (url) => {
        if (url.endsWith(".umd.js")) return false; // skip import for UMD
        try {
          const mod = await import(url);
          // some builds export default; some export namespace
          window.ElevenLabs = mod?.default || mod || window.ElevenLabs;
          return !!(window.ElevenLabs?.Conversation?.startSession);
        } catch {
          return false;
        }
      };

      const tryScript = (url) => new Promise((resolve) => {
        const s = document.createElement("script");
        s.src = url;
        s.async = true;
        s.onload = () => {
          // Older UMDs exposed different globals; check all
          window.ElevenLabs = window.ElevenLabs || window.ElevenLabsClient || window.Eleven || window.Elevenlabs;
          resolve(!!(window.ElevenLabs?.Conversation?.startSession));
        };
        s.onerror = () => resolve(false);
        document.head.appendChild(s);
      });

      for (const url of candidates) {
        let ok = await tryImport(url);
        if (!ok && url.endsWith(".umd.js")) ok = await tryScript(url);
        if (ok) {
          console.log("[SDK] Loaded ElevenLabs from", url);
          return window.ElevenLabs;
        }
        console.warn("[SDK] Failed from", url);
      }

      throw new Error("[SDK] Could not load ElevenLabs SDK from any CDN.");
    };
  </script>

  <style>
    body {
      margin: 0;
      padding: 20px;
      background: #f8fafc;
      font-family: system-ui, -apple-system, sans-serif;
    }
    .tabular-nums { font-variant-numeric: tabular-nums; }
  </style>
</head>
<body>
  <div id="root"></div>

  <script type="text/babel">
    const { useState, useEffect, useRef } = React;

    // === CONFIG ===
    const TOKEN_ENDPOINT = "https://token-server-omrd.onrender.com/api/webrtc-token";

    function VoiceAgentContainer() {
      const [connected, setConnected] = useState(false);
      const [speaking, setSpeaking]   = useState(false);
      const [status, setStatus]       = useState("idle");
      const [elapsed, setElapsed]     = useState(0);
      const [error, setError]         = useState(null);

      // Refs
      const speechStartedRef = useRef(null);
      const rafRef           = useRef(null);
      const speakingRef      = useRef(false);

      // Audio refs (for our analyser/timer only)
      const mediaStreamRef = useRef(null);
      const audioCtxRef    = useRef(null);
      const analyserRef    = useRef(null);
      const sourceRef      = useRef(null);

      // ElevenLabs session
      const conversationRef = useRef(null);

      // Format ms â†’ mm:ss.mmm
      const fmt = (ms) => {
        const mm  = Math.floor(ms / 60000);
        const ss  = Math.floor((ms % 60000) / 1000);
        const ms3 = Math.floor(ms % 1000).toString().padStart(3, "0");
        return `${mm}:${ss.toString().padStart(2, "0")}.${ms3}`;
      };

      // ====== VAD loop (start-once + continuous timer) ======
      const startVadLoop = () => {
        const analyser = analyserRef.current;
        if (!analyser) return;

        const data = new Float32Array(analyser.fftSize);
        const onThreshold  = 0.03;  // ~3% RMS

        const loop = () => {
          analyser.getFloatTimeDomainData(data);
          let sum = 0;
          for (let i = 0; i < data.length; i++) sum += data[i] * data[i];
          const rms = Math.sqrt(sum / data.length);

          // Start the timer the FIRST time we detect voice
          if (!speakingRef.current && rms > onThreshold) {
            speakingRef.current = true;
            setSpeaking(true);
            if (!speechStartedRef.current) {
              speechStartedRef.current = performance.now();
            }
          }

          // Once started, keep timer running continuously
          if (speechStartedRef.current != null) {
            const now = performance.now();
            setElapsed(now - speechStartedRef.current);
          }

          rafRef.current = requestAnimationFrame(loop);
        };

        rafRef.current = requestAnimationFrame(loop);
      };

      const stopVadLoop = () => {
        if (rafRef.current) cancelAnimationFrame(rafRef.current);
        rafRef.current = null;
      };

      // Our analyser-only mic (separate from ElevenLabs internal mic)
      const setupAudioChain = async () => {
        // keep constraints simple to avoid device contention
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        mediaStreamRef.current = stream;

        const Ctx = window.AudioContext || window.webkitAudioContext;
        const ctx = new Ctx();
        audioCtxRef.current = ctx;

        if (ctx.state === "suspended") await ctx.resume();

        const analyser = ctx.createAnalyser();
        analyser.fftSize = 1024;
        analyserRef.current = analyser;

        const src = ctx.createMediaStreamSource(stream);
        sourceRef.current = src;
        src.connect(analyser);

        startVadLoop();
      };

      const teardownAudioChain = () => {
        stopVadLoop();
        try { sourceRef.current?.disconnect(); } catch {}
        try { analyserRef.current?.disconnect(); } catch {}
        if (mediaStreamRef.current) {
          mediaStreamRef.current.getTracks().forEach((t) => t.stop());
          mediaStreamRef.current = null;
        }
        if (audioCtxRef.current) {
          try { audioCtxRef.current.close(); } catch {}
          audioCtxRef.current = null;
        }
        speakingRef.current = false;
        setSpeaking(false);
        speechStartedRef.current = null;
        setElapsed(0);
      };

      // ===== Start / Stop =====
      const handleStart = async () => {
        setError(null);
        setStatus("requesting-mic");

        try {
          // 0) Start analyser mic FIRST so the timer always runs (even if session fails)
          await setupAudioChain();

          // 1) Load SDK
          setStatus("loading-sdk");
          const Eleven = await window.loadElevenLabsSDK();
          if (!Eleven?.Conversation?.startSession) {
            throw new Error("ElevenLabs SDK loaded but Conversation.startSession is missing");
          }

        // 2) Get **signed URL** (NEW)
    setStatus("getting-token");
    const resp = await fetch("https://token-server-omrd.onrender.com/api/webrtc-signed-url", { mode: "cors" });
    if (!resp.ok) {
      const t = await resp.text();
      throw new Error(`Signed URL endpoint error (${resp.status}): ${t}`);
    }
    const { signed_url } = await resp.json();
    if (!signed_url) throw new Error("Signed URL payload missing { signed_url }");

    // 3) Start session with signed URL (NEW)
    setStatus("connecting");
    const session = await Eleven.Conversation.startSession({
      connectionType: "webrtc",
      signedUrl: signed_url
    });

          // Optional: logs for debugging
          session.onStatusChange?.((s) => console.log("[sdk] status:", s));
          session.onError?.((err) => console.error("[sdk] error:", err));

          conversationRef.current = session;

          setConnected(true);
          setStatus("connected");
        } catch (e) {
          // Turn a CloseEvent into a readable message
          let msg = e?.message || String(e);
          if (e && typeof e === "object" && e.type === "close") {
            msg = `WebRTC signaling closed (code=${e.code}, reason=${e.reason || "n/a"})`;
          }
          console.warn("Start failed:", e);
          setStatus("mock-mode");
          setConnected(true); // keep UI usable
          setError(msg);
        }
      };

      const handleStop = async () => {
        try {
          setStatus("stopping");
          const session = conversationRef.current;
          if (session) {
            try {
              if (typeof session.endSession === "function") {
                await session.endSession();
              } else if (typeof session.stopSession === "function") {
                await session.stopSession();
              }
            } catch (e) {
              console.warn("Error stopping session:", e);
            }
            conversationRef.current = null;
          }
        } finally {
          teardownAudioChain();
          setConnected(false);
          setStatus("idle");
          setError(null);
        }
      };

      return (
        <div className="w-full max-w-md mx-auto p-4">
          <div className="rounded-3xl border border-gray-200 shadow-sm p-5 bg-white">
            <div className="flex items-center justify-between mb-4">
              <h1 className="text-lg font-semibold tracking-tight">Korean Grammar Coach</h1>
              <span className={`text-xs px-2 py-1 rounded-full ${
                connected ? "bg-emerald-50 text-emerald-700" :
                ["connecting","requesting-mic","loading-sdk","getting-token"].includes(status) ? "bg-amber-50 text-amber-700" :
                status === "error" ? "bg-rose-50 text-rose-700" :
                status === "mock-mode" ? "bg-blue-50 text-blue-700" :
                "bg-gray-50 text-gray-600"
              }`}>
                {status.replace('-', ' ')}
              </span>
            </div>

            <div className="flex flex-col items-center gap-3 py-6">
              {/* Timer */}
              <div className="text-4xl tabular-nums font-mono">{fmt(elapsed)}</div>

              <div className="text-xs text-gray-500">
                {speaking ? "listeningâ€¦ timer running" : "timer will start when you speak"}
              </div>

              {/* Controls */}
              <div className="flex gap-3 mt-4">
                {!connected ? (
                  <button
                    onClick={handleStart}
                    className="px-4 py-2 rounded-2xl border border-gray-300 hover:bg-gray-50 active:scale-[.99] transition-transform"
                    disabled={["requesting-mic","loading-sdk","getting-token","connecting"].includes(status)}
                  >
                    {status === "requesting-mic" ? "Allow Mic..." :
                     status === "loading-sdk" ? "Loading..." :
                     status === "getting-token" ? "Getting Token..." :
                     status === "connecting" ? "Connecting..." :
                     "Start"}
                  </button>
                ) : (
                  <button
                    onClick={handleStop}
                    className="px-4 py-2 rounded-2xl border border-gray-300 hover:bg-gray-50 active:scale-[.99] transition-transform"
                  >
                    Stop
                  </button>
                )}
              </div>

              {/* Mic visualizer */}
              <MicDot analyser={analyserRef.current} />
            </div>

            {error && (
              <div className="text-sm text-rose-600 border-t pt-4 whitespace-pre-wrap">
                {error}
              </div>
            )}

            <div className="mt-4 text-[11px] text-gray-500 leading-relaxed">
            </div>
          </div>

          <div className="text-[11px] text-gray-400 mt-3 text-center">
            Built for KoreanLearnin
          </div>
        </div>
      );
    }

    function MicDot({ analyser }) {
      const [r, setR] = React.useState(6);

      React.useEffect(() => {
        if (!analyser) return;

        let raf;
        const data = new Float32Array(analyser.fftSize);

        const loop = () => {
          analyser.getFloatTimeDomainData(data);
          let sum = 0;
          for (let i = 0; i < data.length; i++) sum += data[i] * data[i];
          const rms = Math.sqrt(sum / data.length);
          const radius = 6 + Math.min(18, rms * 600);
          setR(radius);
          raf = requestAnimationFrame(loop);
        };

        raf = requestAnimationFrame(loop);
        return () => cancelAnimationFrame(raf);
      }, [analyser]);

      return (
        <div className="mt-2 h-8 flex items-center justify-center">
          <div
            aria-hidden
            className="rounded-full transition-all duration-75"
            style={{ width: r * 2, height: r * 2, background: "#111", opacity: 0.8 }}
          />
        </div>
      );
    }

    const root = ReactDOM.createRoot(document.getElementById('root'));
    root.render(<VoiceAgentContainer />);
  </script>
</body>
</html>
