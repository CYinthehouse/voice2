<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Korean Grammar Coach</title>

  <!-- React + Babel + Tailwind -->
  <script crossorigin src="https://unpkg.com/react@18/umd/react.development.js"></script>
  <script crossorigin src="https://unpkg.com/react-dom@18/umd/react-dom.development.js"></script>
  <script src="https://unpkg.com/@babel/standalone/babel.min.js"></script>
  <script src="https://cdn.tailwindcss.com"></script>

  <!-- Robust SDK loader: tries multiple CDNs/versions and sets window.ElevenLabs -->
  <script type="module">
    window.loadElevenLabsSDK = async function loadElevenLabsSDK() {
      if (window.ElevenLabs) return window.ElevenLabs;

      // Known-working builds (try ESM first, then UMD)
      const candidates = [
        // jsDelivr 0.6.x (ESM)
        "https://cdn.jsdelivr.net/npm/@elevenlabs/client@0.6.2/dist/lib.modern.js",
        "https://cdn.jsdelivr.net/npm/@elevenlabs/client@0.6.1/dist/lib.modern.js",
        "https://cdn.jsdelivr.net/npm/@elevenlabs/client@0.6.0/dist/lib.modern.js",
        // jsDelivr 0.1.6 (ESM + UMD)
        "https://cdn.jsdelivr.net/npm/@elevenlabs/client@0.1.6/dist/lib.modern.js",
        "https://cdn.jsdelivr.net/npm/@elevenlabs/client@0.1.6/dist/lib.umd.js"
      ];

      const tryImport = async (url) => {
        if (url.endsWith(".umd.js")) return false; // skip import for UMD
        try {
          const mod = await import(url);
          window.ElevenLabs = mod || window.ElevenLabs;
          return !!window.ElevenLabs;
        } catch {
          return false;
        }
      };

      const tryScript = (url) => new Promise((resolve) => {
        const s = document.createElement("script");
        s.src = url;
        s.async = true;
        s.onload = () => {
          // Older UMDs exposed different globals; check all
          window.ElevenLabs = window.ElevenLabs || window.ElevenLabsClient || window.Eleven;
          resolve(!!window.ElevenLabs);
        };
        s.onerror = () => resolve(false);
        document.head.appendChild(s);
      });

      for (const url of candidates) {
        let ok = await tryImport(url);
        if (!ok && url.endsWith(".umd.js")) ok = await tryScript(url);
        if (ok && window.ElevenLabs?.Conversation?.startSession) {
          console.log("[SDK] Loaded ElevenLabs from", url);
          return window.ElevenLabs;
        }
        console.warn("[SDK] Failed from", url);
      }

      throw new Error("[SDK] Could not load ElevenLabs SDK from any CDN.");
    };
  </script>

  <style>
    body {
      margin: 0;
      padding: 20px;
      background: #f8fafc;
      font-family: system-ui, -apple-system, sans-serif;
    }
    .tabular-nums { font-variant-numeric: tabular-nums; }
  </style>
</head>
<body>
  <div id="root"></div>

  <script type="text/babel">
    const { useState, useEffect, useRef } = React;

    // Your Render backend token endpoint
    const TOKEN_ENDPOINT = "https://token-server-omrd.onrender.com/api/webrtc-token";

    function VoiceAgentContainer() {
      const [connected, setConnected] = useState(false);
      const [speaking, setSpeaking]   = useState(false);
      const [status, setStatus]       = useState("idle");
      const [elapsed, setElapsed]     = useState(0);
      const [error, setError]         = useState(null);

      // Refs
      const speechStartedRef = useRef(null);
      const rafRef           = useRef(null);
      const speakingRef      = useRef(false);

      // Audio refs
      const mediaStreamRef = useRef(null);
      const audioCtxRef    = useRef(null);
      const analyserRef    = useRef(null);
      const sourceRef      = useRef(null);

      // ElevenLabs session
      const conversationRef = useRef(null);

      // Format ms → mm:ss.mmm
      const fmt = (ms) => {
        const mm  = Math.floor(ms / 60000);
        const ss  = Math.floor((ms % 60000) / 1000);
        const ms3 = Math.floor(ms % 1000).toString().padStart(3, "0");
        return `${mm}:${ss.toString().padStart(2, "0")}.${ms3}`;
      };

  // ====== VAD loop (start-once + continuous timer) ======
const startVadLoop = () => {
  const analyser = analyserRef.current;
  if (!analyser) return;

  const data = new Float32Array(analyser.fftSize);
  const onThreshold  = 0.03;  // ~3% RMS

  const loop = () => {
    analyser.getFloatTimeDomainData(data);
    let sum = 0;
    for (let i = 0; i < data.length; i++) sum += data[i] * data[i];
    const rms = Math.sqrt(sum / data.length);

    // Start the timer the FIRST time we detect voice
    if (!speakingRef.current && rms > onThreshold) {
      speakingRef.current = true;
      setSpeaking(true);
      if (!speechStartedRef.current) {
        speechStartedRef.current = performance.now();
      }
    }

    // Once started, keep timer running continuously
    if (speechStartedRef.current != null) {
      const now = performance.now();
      setElapsed(now - speechStartedRef.current);
    }

    // (We no longer set speaking=false on quiet — mic dot still animates fine)
    rafRef.current = requestAnimationFrame(loop);
  };

  rafRef.current = requestAnimationFrame(loop);
};


      const stopVadLoop = () => {
        if (rafRef.current) cancelAnimationFrame(rafRef.current);
        rafRef.current = null;
      };

      const setupAudioChain = async () => {
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        mediaStreamRef.current = stream;

        const Ctx = window.AudioContext || window.webkitAudioContext;
        const ctx = new Ctx();
        audioCtxRef.current = ctx;

        if (ctx.state === "suspended") await ctx.resume();

        const analyser = ctx.createAnalyser();
        analyser.fftSize = 1024;
        analyserRef.current = analyser;

        const src = ctx.createMediaStreamSource(stream);
        sourceRef.current = src;
        src.connect(analyser);

        startVadLoop();
      };

      const teardownAudioChain = () => {
        stopVadLoop();
        try { sourceRef.current?.disconnect(); } catch {}
        try { analyserRef.current?.disconnect(); } catch {}
        if (mediaStreamRef.current) {
          mediaStreamRef.current.getTracks().forEach((t) => t.stop());
          mediaStreamRef.current = null;
        }
        if (audioCtxRef.current) {
          try { audioCtxRef.current.close(); } catch {}
          audioCtxRef.current = null;
        }
        speakingRef.current = false;
        setSpeaking(false);
        speechStartedRef.current = null;
        setElapsed(0);
      };

const handleStart = async () => {
  setError(null);
  setStatus("requesting-mic");

  try {
    // ✅ 1) Load SDK *before* we touch the mic, so we can let SDK own it
    setStatus("loading-sdk");
    const Eleven = await window.loadElevenLabsSDK();
    if (!Eleven?.Conversation?.startSession) {
      throw new Error("ElevenLabs SDK loaded but Conversation.startSession is missing");
    }

    // ✅ 2) Get token
    setStatus("getting-token");
    const resp = await fetch(TOKEN_ENDPOINT);
    if (!resp.ok) {
      const t = await resp.text();
      throw new Error(`Token endpoint error (${resp.status}): ${t}`);
    }
    const { token } = await resp.json();
    if (!token) throw new Error("Token payload missing { token }");

    // ✅ 3) Start WebRTC session (let SDK open mic itself)
    setStatus("connecting");
    const session = await Eleven.Conversation.startSession({
      connectionType: "webrtc",
      conversationToken: token,
      // Some SDK builds accept this flag; harmless if ignored:
      enableMicrophone: true
    });

    conversationRef.current = session;

    // ✅ 4) Now create *your own* analyser mic for the dot/timer (does not affect SDK)
    await setupAudioChain();

    setConnected(true);
    setStatus("connected");
  } catch (e) {
    console.warn("Start failed:", e);
    setStatus("mock-mode");
    setConnected(true); // keep UI usable
    setError(e.message || String(e));
  }
};

      const handleStop = async () => {
        try {
          setStatus("stopping");
          const session = conversationRef.current;
          if (session) {
            try {
              if (typeof session.endSession === "function") {
                await session.endSession();
              } else if (typeof session.stopSession === "function") {
                await session.stopSession();
              }
            } catch (e) {
              console.warn("Error stopping session:", e);
            }
            conversationRef.current = null;
          }
        } finally {
          teardownAudioChain();
          setConnected(false);
          setStatus("idle");
          setError(null);
        }
      };

      return (
        <div className="w-full max-w-md mx-auto p-4">
          <div className="rounded-3xl border border-gray-200 shadow-sm p-5 bg-white">
            <div className="flex items-center justify-between mb-4">
              <h1 className="text-lg font-semibold tracking-tight">Korean Grammar Coach</h1>
              <span className={`text-xs px-2 py-1 rounded-full ${
                connected ? "bg-emerald-50 text-emerald-700" :
                ["connecting","requesting-mic","loading-sdk","getting-token"].includes(status) ? "bg-amber-50 text-amber-700" :
                status === "error" ? "bg-rose-50 text-rose-700" :
                status === "mock-mode" ? "bg-blue-50 text-blue-700" :
                "bg-gray-50 text-gray-600"
              }`}>
                {status.replace('-', ' ')}
              </span>
            </div>

            <div className="flex flex-col items-center gap-3 py-6">
              {/* Timer */}
              <div className="text-4xl tabular-nums font-mono">{fmt(elapsed)}</div>

              <div className="text-xs text-gray-500">
                {speaking ? "listening… timer running" : "timer will start when you speak"}
              </div>

              {/* Controls */}
              <div className="flex gap-3 mt-4">
                {!connected ? (
                  <button
                    onClick={handleStart}
                    className="px-4 py-2 rounded-2xl border border-gray-300 hover:bg-gray-50 active:scale-[.99] transition-transform"
                    disabled={["requesting-mic","loading-sdk","getting-token","connecting"].includes(status)}
                  >
                    {status === "requesting-mic" ? "Allow Mic..." :
                     status === "loading-sdk" ? "Loading..." :
                     status === "getting-token" ? "Getting Token..." :
                     status === "connecting" ? "Connecting..." :
                     "Start"}
                  </button>
                ) : (
                  <button
                    onClick={handleStop}
                    className="px-4 py-2 rounded-2xl border border-gray-300 hover:bg-gray-50 active:scale-[.99] transition-transform"
                  >
                    Stop
                  </button>
                )}
              </div>

              {/* Mic visualizer */}
              <MicDot analyser={analyserRef.current} />
            </div>

            {error && (
              <div className="text-sm text-rose-600 border-t pt-4 whitespace-pre-wrap">
                {error}
              </div>
            )}

            <div className="mt-4 text-[11px] text-gray-500 leading-relaxed">
              <strong>Secure Setup:</strong> Token server at token-server-omrd.onrender.com
              <br />• API keys stay on the server
              <br />• Temporary tokens only
              <br />• No secrets in the browser
            </div>
          </div>

          <div className="text-[11px] text-gray-400 mt-3 text-center">
            Built for @askcalvinoppa · Minimal container · Timer starts on speech
          </div>
        </div>
      );
    }

    function MicDot({ analyser }) {
      const [r, setR] = React.useState(6);

      React.useEffect(() => {
        if (!analyser) return;

        let raf;
        const data = new Float32Array(analyser.fftSize);

        const loop = () => {
          analyser.getFloatTimeDomainData(data);
          let sum = 0;
          for (let i = 0; i < data.length; i++) sum += data[i] * data[i];
          const rms = Math.sqrt(sum / data.length);
          const radius = 6 + Math.min(18, rms * 600);
          setR(radius);
          raf = requestAnimationFrame(loop);
        };

        raf = requestAnimationFrame(loop);
        return () => cancelAnimationFrame(raf);
      }, [analyser]);

return (
  <div className="mt-2 h-8 flex items-center justify-center">
    <div
      aria-hidden
      className="rounded-full transition-all duration-75"
      style={{ width: r * 2, height: r * 2, background: "#111", opacity: 0.8 }}
    />
  </div>
);
    }

    const root = ReactDOM.createRoot(document.getElementById('root'));
    root.render(<VoiceAgentContainer />);
  </script>
</body>
</html>
